{
 "metadata": {
  "name": "",
  "signature": "sha256:7f0b2fb2740b2f31279e03ca37fdab4ec4ec9fe360e93f5f90e74b90cbf9d7f8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "print(__doc__)\n",
      "\n",
      "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
      "# License: BSD\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from scipy.ndimage import convolve\n",
      "from sklearn import linear_model, datasets, metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "# Setting up\n",
      "\n",
      "def nudge_dataset(X, Y):\n",
      "    \"\"\"\n",
      "    This produces a dataset 5 times bigger than the original one,\n",
      "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
      "    \"\"\"\n",
      "    direction_vectors = [\n",
      "        [[0, 1, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [1, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 1],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 1, 0]]]\n",
      "\n",
      "    shift = lambda x, w: convolve(x.reshape((8, 8)), mode='constant',\n",
      "                                  weights=w).ravel()\n",
      "    X = np.concatenate([X] +\n",
      "                       [np.apply_along_axis(shift, 1, X, vector)\n",
      "                        for vector in direction_vectors])\n",
      "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
      "    return X, Y\n",
      "\n",
      "# Load Data\n",
      "digits = datasets.load_digits()\n",
      "X = np.asarray(digits.data, 'float32')\n",
      "X, Y = nudge_dataset(X, digits.target)\n",
      "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
      "\n",
      "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
      "                                                    test_size=0.2,\n",
      "                                                    random_state=0)\n",
      "\n",
      "# Models we will use\n",
      "logistic = linear_model.LogisticRegression()\n",
      "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
      "\n",
      "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
      "\n",
      "###############################################################################\n",
      "# Training\n",
      "\n",
      "# Hyper-parameters. These were set by cross-validation,\n",
      "# using a GridSearchCV. Here we are not performing cross-validation to\n",
      "# save time.\n",
      "rbm.learning_rate = 0.06\n",
      "rbm.n_iter = 20\n",
      "# More components tend to give better prediction performance, but larger\n",
      "# fitting time\n",
      "rbm.n_components = 100\n",
      "logistic.C = 6000.0\n",
      "\n",
      "# Training RBM-Logistic Pipeline\n",
      "classifier.fit(X_train, Y_train)\n",
      "\n",
      "# Training Logistic regression\n",
      "logistic_classifier = linear_model.LogisticRegression(C=100.0)\n",
      "logistic_classifier.fit(X_train, Y_train)\n",
      "\n",
      "###############################################################################\n",
      "# Evaluation\n",
      "\n",
      "print()\n",
      "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        Y_test,\n",
      "        classifier.predict(X_test))))\n",
      "\n",
      "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        Y_test,\n",
      "        logistic_classifier.predict(X_test))))\n",
      "\n",
      "###############################################################################\n",
      "# Plotting\n",
      "\n",
      "plt.figure(figsize=(4.2, 4))\n",
      "for i, comp in enumerate(rbm.components_):\n",
      "    plt.subplot(10, 10, i + 1)\n",
      "    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r,\n",
      "               interpolation='nearest')\n",
      "    plt.xticks(())\n",
      "    plt.yticks(())\n",
      "plt.suptitle('100 components extracted by RBM', fontsize=16)\n",
      "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Automatically created module for IPython interactive environment\n",
        "Iteration 0, pseudo-likelihood = -28.84, time = 0.61s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 1, pseudo-likelihood = -25.92, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 2, pseudo-likelihood = -24.82, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 3, pseudo-likelihood = -23.71, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 4, pseudo-likelihood = -23.03, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 5, pseudo-likelihood = -22.44, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 6, pseudo-likelihood = -21.91, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 7, pseudo-likelihood = -21.66, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 8, pseudo-likelihood = -21.39, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 9, pseudo-likelihood = -21.07, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 10, pseudo-likelihood = -20.85, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 11, pseudo-likelihood = -20.74, time = 0.59s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 12, pseudo-likelihood = -20.57, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 13, pseudo-likelihood = -20.44, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 14, pseudo-likelihood = -20.29, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 15, pseudo-likelihood = -20.20, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 16, pseudo-likelihood = -19.98, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 17, pseudo-likelihood = -19.75, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 18, pseudo-likelihood = -19.78, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 19, pseudo-likelihood = -19.67, time = 0.60s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic regression using RBM features:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.99      0.99      0.99       174\n",
        "          1       0.92      0.95      0.93       184\n",
        "          2       0.95      0.98      0.97       166\n",
        "          3       0.97      0.91      0.94       194\n",
        "          4       0.97      0.95      0.96       186\n",
        "          5       0.93      0.93      0.93       181\n",
        "          6       0.98      0.97      0.97       207\n",
        "          7       0.95      1.00      0.97       154\n",
        "          8       0.90      0.88      0.89       182\n",
        "          9       0.91      0.93      0.92       169\n",
        "\n",
        "avg / total       0.95      0.95      0.95      1797\n",
        "\n",
        "\n",
        "Logistic regression using raw pixel features:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.85      0.94      0.89       174\n",
        "          1       0.57      0.55      0.56       184\n",
        "          2       0.72      0.85      0.78       166\n",
        "          3       0.76      0.74      0.75       194\n",
        "          4       0.85      0.82      0.84       186\n",
        "          5       0.74      0.75      0.75       181\n",
        "          6       0.93      0.88      0.91       207\n",
        "          7       0.86      0.90      0.88       154\n",
        "          8       0.68      0.55      0.61       182\n",
        "          9       0.71      0.74      0.72       169\n",
        "\n",
        "avg / total       0.77      0.77      0.77      1797\n",
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/numpy-1.9.2-py2.7-macosx-10.9-intel.egg/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
        "  VisibleDeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}