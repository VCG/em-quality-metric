\section{Introduction}

% JT: Trying to write short, as we have only 8 pages.
%\JT{EVERYONE: I am a bit concerned about two reductionist arguments that will be thrown at us: 1. why don't we just try and make the initial segmentation better? 2. at the limit, someone still has to scan the whole volume because your edge error classifier is often wrong. Any ideas?}

%Paragraph one: Provide context to the work.
%What is the task? What is the state of the task?
In connectomics, neuroanatomists build 3D reconstructions of neuron connectivity to gain insight into the functional structure of the brain. Rapid progress in automatic sample preparation and electron microscopy (EM) acquisition techniques has made it possible to image volumes of brain tissue at $\approx6nm$ per pixel to identify synapses and vesicles. For a section $25nm$ thick, a $1 mm^3$ volume of brain tissue contains $10^{15}$ voxels, or 1 petabyte of data. Manual annotation of data this large is unfeasible, and automatic methods are needed \cite{jain2010,kaynig13,Liu2014,NunezIglesias2013Machine,GALA2014,amelio_segmentation}.

Automatic segmentation and classification of brain tissue is hard in cases with ambiguous intercellular space \cite{isbi_challenge}, so learning-based methods are common. These can be based on interactive learning with random forests \cite{neuroproof2013,amelio_segmentation,kaynig13}, or supervised learning with convolutional neural networks \cite{RonnebergerFB15,lee2015recursive}, or potentially even with unsupervised learning \cite{BogovicHJ13}. Typically, cell membranes are learned in 2D images and then grouped into geometrically-consistent cell regions across registered sections to form 3D volumes, or learned across registered sections in 3D directly. Using dynamic programming techniques \VKF{cite cdd whole image training paper}, and small GPU clusters, these classifiers can segment about 1 terabyte of data per hour \cite{kasthuri2015saturated}, and so `keep up' with the data capture process on state-of-the-art electron microscopes.

%State of the art methods use convolutional neural networks to learn cell membranes in 2D images from hand-labeled training data. Then, labeled membranes are grouped into geometrically-consistent cell regions across sections to form 3D image stacks. Using dynamic programming techniques \VKF{cite cdd whole image training paper}, and small GPU clusters \VKF{how many?}, these classifiers can segment about 1 terabyte of data per hour \cite{kasthuri2015saturated,lee2015recursive}, which is the rate necessary to keep up with the data capture process on state-of-the-art electron microscopes. %\VKF{citation for 61 beam microscope?}. \JT{I would skip. There is a Nature press piece (see comment in source), but is there a peer-reviewed academic article? Also, I cited the recent Cell paper for the segmentation rates above; I hope that is ok.} % \url{http://www.nature.com/nature/journal/v503/n7474/full/503147a.html?WT.ec_id=NATURE-20131107}

%Paragraph two: What is the problem in this context? What is the situation that you are trying to correct or overcome?
However, all automatic methods are at least somewhat erroneous, and we are left with large volumes of data which need \emph{proofreading}. This crucial task serves two purposes: 1) to correct errors in the segmentation for later use, and critically 2) to provide larger corpora of labeled data to train better automatic segmentation methods. Recent interactive proofreading tools provide intuitive user interfaces to browse segmentation data in 2D and 3D and identify and manually correct errors \cite{markus_proofreading,raveler,mojo2,haehn_dojo_2014}. Many kinds of errors exist, such as inaccurate boundaries, but the most egregious are \emph{split errors}, where a single cell is labeled as two, and \emph{merge errors}, where two cells are labeled as one. With user interaction, split errors can be joined, and the missing edge in merge errors can be discovered with techniques like manually-seeded watersheds \cite{haehn_dojo_2014}. However, even with these `semi-automatic' correction tools, the visual inspection of the data to find the errors in the first place takes the majority of the time.

%Paragraph three: What is the proposed solution at a high level? What is the result of the method, and how does it impact the problem?
Our goal is to complement semi-automatic correction tools with semi-automatic error finding. Instead of having to visually inspect the whole data volume carefully to spot any errors, we design two automatic classifiers which detect both split and merge errors in 2D segmentations, to direct the user to regions with a high probability of an error. Then, we suggest probable error corrections for the user to accept or reject. Given an initial membrane segmentation from an automatic method, our classifiers operate on whole cell regions. This significantly reduces the data volume and allows us to employ large convolutional neural networks which take a greater region of context and multiple input channels into account.

One major reason for attempting to classify errors on 2D images is with the scale of the task. 3D reconstruction pipelines are often slow as they require non-linear image alignment or registration \cite{akselrod09,beyer13,Saalfeld2010Asrigidaspossible}. However, typically segmentation results are local decisions at the cell level. In this case, reconstruction is unnecessary and, instead of waiting for the 3D output, proofreading can start immediately to maximize throughput.

%Paragraph five: Optimistically, what is the consequence of the method - what can I do now that I could not do before?
We validate our approach in a purely automatic mode, and in an experiment against an existing proofreading tool with only semi-automatic merge error correction\cite{haehn_dojo_2014}. We discover that our automatic corrections reduces variation of information (VI) vs.~ground truth expert segmentations from 0.59 to 0.49, and that, with users, our automatic error suggestions and corrections can potentially decrease VI from 0.56 to 0.48. As a consequence, we are able to provide tools to proofread segmentations more efficiently, from which to improve automatic segmentation methods and better tackle vast volumes of connectomics imagery.

%\subsection{Contributions}
%
%Given this, we contribute to the literature:
%\begin{enumerate}
%\item One contribution
%\item Two contribution
%\item (Maybe) three contribution
%\end{enumerate}

\begin{figure}
\missingfigure{Example of a fixed split error. Example of a fixed merge error.}
\caption{Example of a fixed split error. Example of a fixed merge error.}
\end{figure}