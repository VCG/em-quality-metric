\section{Method}
%Paragraph one: Overview of the method. What are the high level steps taken to build the system? What are the key techniques used within the system?
We build a split error classifier using a convolutional neural network (CNN) to scan the boundaries of an existing automatic multi-label segmentation (for which there are many methods \cite{jain2010,kaynig13,Liu2014,NunezIglesias2013Machine,GALA2014,amelio_segmentation}). For each boundary, our classifier provides a probability that sample points along the boundary caused a split error. These samples are then combined into a final edge score. Correcting a split error is as simple as merging the two bordering labels, either automatically based on a score threshold, or through highlighting to the user a likely error boundary.

Identification and correction of merge errors is slower and more challenging, because we must look inside segmentation regions for missing or incomplete boundaries, and then propose the correct boundary. However, we can reuse the same trained CNN for this task. For each segmentation label, we generate 20\JT{check} potential boundaries through the middle of the region by placing seed points to a watershed cut along the opposite edges of the label boundary. Then, we check to see whether any potential edge is classified a split error as before. If the CNN detects a boundary with a very low split error score, then the boundary should have been in the segmentation and is a candidate for a merge error.

\begin{figure}[t]
\centering
\includegraphics[scale=.15]{gfx/patches.pdf}
\caption{Show visually each of the inputs to the system on a couple of patches.}
\end{figure}


\subsection{Network Design}
%Paragraph: What is the rationale behind our network design? Why do we think this will work over other approaches?
One typical way to train a CNN for boundary detection is to take in the wider context of the boundary in the decision making process. This is accomplished by passing in as inputs to the CNN the outputs of an automatic segmentation method windowed around a particular decision point or pixel: the input grayscale image patch, the corresponding boundary probability map patch, and two corresponding binary mask patches for the regions either side of the boundary. Following Bogovic et al.~\cite{BogovicHJ13}, these two masks can be combined into a single mask with comparable performance. The network then leverages these multiple input patches to identify and correct errors made by the previous membrane detection network and automatic segmentation pipeline.

One classic way to combine these inputs is to treat them as a 3-channel input, so that alignment between the input image and the segmentation masks are not lost throughout the convolutions. However, training a boundary-classifying network can be difficult due to rigid ground-truth segmentations, which often differ substantially from automatic segmentation regions in ambiguous intercellular space. To cope with this variation, instead our network is based on multiple separate input channels (Fig.~\ref{fig:layers}). Each of the input patches is connected individually to a 2-layer network, with each layer consisting of convolutional and pooling layers. The output of these networks is then combined by a fully connected multi-layer perceptron (MLP) with one hidden layer and a two class logistic regression output layer. The intuition for this multiple input channel approach is that we want to allow variation in the input and masks independently, to accommodate potential error, and then for the hidden layers to discover appropriate combinations\JT{of what??}.

Another change is in the pooling layer itself. Bogovic et al.~\cite{BogovicHJ13} designed an unsupervised learning approach for agglomerative clustering of oversegmentations, using dynamic pooling of features extracted around objects and boundaries to increase performance. Inspired by their call for a supervised learning equivalent, we integrate a pooling layer into our CNN which is similar in spirit to their unsupervised approach. Instead of conventional max- or avg-pooling where a sliding window is equally applied to the whole output of the convolutional layer, our dynamic pooling only averages outputs within a region of interest. We implemented both pooling methods and compared them \VKF{reference to result table}.

\JT{Up to here.}
\begin{figure}[t]
 \centering
    \subfloat[CNN Layers\label{fig:layers}]{%
      \includegraphics[width=0.55\textwidth]{gfx/layers.pdf}
    }
    \hfill
    \subfloat[Network configurations\label{fig:networks}]{%
      \includegraphics[width=0.4\textwidth]{gfx/networks.pdf}
    }
	\caption{a) Our proposed network architecture with up to four input channels. Each input channel involves two convolutional and two pooling layers with optional dynamic pooling using a binary mask as described by Bogovic et al \cite{viren}. b) We trained five different network configurations with three and four inputs: A) image, probability and merged binary mask, B) extended with a small border mask, C) extended with a large border mask and D)+E) using a single label binary mask instead of the merged one with the small and large border mask.}
\end{figure}
%  
%    \begin{subfig}[b]{0.5\textwidth}
%        \includegraphics[scale=.15]
%        \caption{CNN Layers}
%        \label{fig:layers}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.5\textwidth}
%        \includegraphics[scale=.15]
%        \caption{Different Network Configurations}
%        \label{fig:networks}
%    \end{subfigure}    
%\missingfigure{Network architecture figure}



\subsection{Training}

To train the network, we used a dataset of a mouse cortex (1024x1024x75 pixels). The tissue is dense mammalian neuropil from layers 4 and 5 of the S1 primary somatosensory cortex of a healthy mouse. The resolution of our data set is 6nm/pixel and the section thickness is 30nm. We trained an automatic segmentation pipeline on a similar dataset and used it to segment the data \cite{rhoana}. Manually labeled expert segmentation was available as a ground truth for the entire dataset. We used the first 65 sections of the data for training, the next 5 for validation and the last 5 for testing.
%#   Training data:
%#   Patch size: (75,75)
%#   79828 correct splits
%#   79828 split errors
%#   rotated 90,180,270 degrees after each epoch
%
%#   validation data: 7464 correct splits + 7464 split errors
%#   test data: 5748 correct splits + 5748 split errors
First, we generated patches using the ground truth and simulated split errors via watershed. This approach did not work since the ground truth labeling did not include extra=cellular structures and applying the classifier to the dense segmentation output of our pipeline failed. Therefor, we performed maximum overlap between the ground truth and our automatic segmentation output. The difference in borders in our automatic segmentation and the maximum overlap segmentation were our errors. We generated 79828 correct splits and 79828 split error patches using this method.

After a grid exploration of parameters for filter size, number of filters, batch size, learning rate and momentum, we found the following parameters: learning rate $lr=.00001$, momentum $m=.9$, filter size $fs=13x13$ and number of filters $fn=16$. We configured the network using Theano/Lasagne and ran the training on a Tesla K40m graphics hardware. We stopped once the training loss did not decrease anymore for 30 epochs.



\begin{table}
\begin{tabular}{ll}
\toprule
Parameter & Value \\
\midrule
one & \\
two & \\
three & \\
\bottomrule
\end{tabular}
\caption{This is a table of parameters. This is not very interesting, but it's easier to read than in the body text and putting everything together helps the reader quickly assess.}
\end{table}