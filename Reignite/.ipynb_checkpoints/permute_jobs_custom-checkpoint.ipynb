{
 "metadata": {
  "name": "",
  "signature": "sha256:662e31326986101180a73e4d38cb5ba3cf4d498437f9a788042e2e494e9ee125"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "# LAUNCH THE JOBS WITH:\n",
      "# for f in *.slurm; do sbatch $f; done\n",
      "#\n",
      "\n",
      "import os\n",
      "import sys\n",
      "from string import Template\n",
      "import uuid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PATCH_PATH = 'patches_4th'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "OUTPUT_PATH = 'custom_slurm/'+PATCH_PATH+'/'\n",
      "\n",
      "if not os.path.exists(OUTPUT_PATH):\n",
      "    os.makedirs(OUTPUT_PATH)\n",
      "\n",
      "slurm_header = \"\"\"#!/bin/bash\n",
      "#\n",
      "# add all other SBATCH directives here...\n",
      "#\n",
      "#SBATCH -p holyseasgpu\n",
      "#SBATCH --gres=gpu\n",
      "#SBATCH -n 1 # Number of cores\n",
      "#SBATCH -N 1 # Ensure that all cores are on one machine\n",
      "#SBATCH --gres=gpu\n",
      "#SBATCH --mem=24000\n",
      "#SBATCH -t 7-12:00\n",
      "#SBATCH --mail-type=ALL\n",
      "#SBATCH --mail-user=haehn@seas.harvard.edu\n",
      "#SBATCH -o /n/home05/haehn/slurm/out-$uuid.txt\n",
      "#SBATCH -e /n/home05/haehn/slurm/err-$uuid.txt\n",
      "\n",
      "# add additional commands needed for Lmod and module loads here\n",
      "source new-modules.sh\n",
      "#module load gcc/4.8.2-fasrc01 python/2.7.9-fasrc01\n",
      "module load Anaconda/2.1.0-fasrc01\n",
      "#module load cuda/7.5-fasrc01\n",
      "export CUDA_HOME=/usr/local/cuda-7.0\n",
      "export CUDA_LIB=/usr/local/cuda-7.0/lib64\n",
      "export CUDA_INCLUDE=/usr/local/cuda-7.0/include\n",
      "export PATH=/usr/local/cuda-7.0/bin:$PATH\n",
      "export CPATH=/usr/local/cuda-7.0/include:$CPATH\n",
      "export FPATH=/usr/local/cuda-7.0/include:$FPATH\n",
      "export LD_LIBRARY_PATH=/usr/local/cuda-7.0/lib:$LD_LIBRARY_PATH\n",
      "export LIBRARY_PATH=/usr/local/cuda-7.0/lib:$LIBRARY_PATH\n",
      "export LD_LIBRARY_PATH=/usr/local/cuda-7.0/lib64:$LD_LIBRARY_PATH\n",
      "export LIBRARY_PATH=/usr/local/cuda-7.0/lib64:$LIBRARY_PATH\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "slurm_body = Template(\"\"\"\n",
      "# add commands for analyses here\n",
      "cd /n/home05/haehn/Projects/em-quality-metric/Reignite/\n",
      "python train.py -r cluster --patchpath $patchpath --epochs $epochs --batchsize $batchsize --learning_rate $learning_rate --momentum $momentum --filters1 $no_filters --filters2 $no_filters --filters3 $no_filters --filtersize1 $filter_size --filtersize2 $filter_size --filtersize3 $filter_size --thirdconvlayer $thirdconvlayer --inputs $inputs --uuid $uuid\n",
      "\n",
      "# end of program\n",
      "exit 0;\n",
      "\"\"\")\n",
      "\n",
      "\n",
      "epochs = [500]\n",
      "batchsize = [500]#,1000]#,5000]#[100, 500, 1000]\n",
      "learning_rate = [0.00001]#, 0.01]#[0.000001, 0.00001, 0.0001, 0.001, 0.01]\n",
      "momentum = [0.9]\n",
      "thirdconvlayer = [True]\n",
      "no_filters = [16]\n",
      "filter_size = [13]\n",
      "inputs = {'mine':'image prob binary border_overlap',\n",
      "          'mine_large':'image prob binary larger_border_overlap',\n",
      "          'viren':'image prob merged_array dyn_obj dyn_bnd',\n",
      "          'viren_overlap':'image prob merged_array dyn_obj dyn_bnd border_overlap',\n",
      "          'viren_large':'image prob merged_array dyn_obj dyn_bnd larger_border_overlap'}\n",
      "\n",
      "\n",
      "no_jobs = 0\n",
      "\n",
      "for e in epochs:\n",
      "  for b in batchsize:\n",
      "    for l in learning_rate:\n",
      "      for m in momentum:\n",
      "        for c in thirdconvlayer:\n",
      "          for n in no_filters:\n",
      "            for s in filter_size:\n",
      "              for i in inputs.keys():\n",
      "              \n",
      "                  input = inputs[i]\n",
      "              \n",
      "                  no_jobs += 1\n",
      "                  uniqueid = i#str(uuid.uuid4())\n",
      "\n",
      "                  new_slurm_body = slurm_body.substitute(patchpath=PATCH_PATH, epochs=e, batchsize=b, learning_rate=l, momentum=m, thirdconvlayer=c, no_filters=n, filter_size=s, uuid=uniqueid, inputs=input)\n",
      "                  slurm = slurm_header.replace('$uuid', uniqueid) + new_slurm_body\n",
      "\n",
      "                  with open(OUTPUT_PATH+PATCH_PATH+str(i)+'.slurm', 'w') as f:\n",
      "                    f.write(slurm)\n",
      "\n",
      "\n",
      "print no_jobs, 'slurms generated.'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12 slurms generated.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}