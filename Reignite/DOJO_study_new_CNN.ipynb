{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cnn import CNN\n",
    "from dyn_cnn import DynCNN\n",
    "from util import Util\n",
    "from patch import Patch\n",
    "from fixer import Fixer\n",
    "from uglify import Uglify\n",
    "\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import mahotas as mh\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import mlproof as mlp\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOJO_USER_DATA_FOLDER = '/home/d/Dropbox/DOJOSTUDY/'\n",
    "DOJO_USERS_IDS = [11,13,18,37,40,43,5,50,53,62]\n",
    "DOJO_USERS = []\n",
    "for d in DOJO_USERS_IDS:\n",
    "    DOJO_USERS.append('S'+str(d)+'tif')\n",
    "    \n",
    "def read_user(user, slice):\n",
    "    img = mh.imread(DOJO_USER_DATA_FOLDER+user+os.sep+'z='+str(slice).zfill(8)+'.tif')\n",
    "    img = Util.crop_by_bbox(img, dojo_bbox)\n",
    "    return Util.frame_image(img)\n",
    "\n",
    "def dojo_user_vi(user, slice, gt):\n",
    "    img = read_user(user, slice)\n",
    "    return Util.vi(img, gt)\n",
    "\n",
    "def fix_dojo_slice(cnn, slice, input_image, input_prob, input_rhoana, input_gold,t=0.):\n",
    "    DOJO_SLICE=slice\n",
    "    vi_s, merge_pairs, surenesses = Fixer.splits(cnn, \n",
    "                                                 input_image[DOJO_SLICE], \n",
    "                                                 input_prob[DOJO_SLICE], \n",
    "                                                 input_rhoana[DOJO_SLICE], \n",
    "                                                 input_gold[DOJO_SLICE],\n",
    "                                                 sureness_threshold=t,\n",
    "                                                 oversampling=False)\n",
    "\n",
    "    best_index = vi_s.index(np.min(vi_s))\n",
    "    best_vi = vi_s[best_index]\n",
    "    best_sureness = surenesses[best_index]\n",
    "    \n",
    "    return best_vi, best_sureness, vi_s, surenesses\n",
    "\n",
    "def fix_dojo_slice_user_simulated(cnn, slice, input_image, input_prob, input_rhoana, input_gold, error_rate=0,t=0):\n",
    "    DOJO_SLICE=slice\n",
    "    vi_s, merge_pairs, surenesses, good_fixes, bad_fixes = Fixer.splits_user_simulated(cnn, \n",
    "                                                 input_image[DOJO_SLICE], \n",
    "                                                 input_prob[DOJO_SLICE], \n",
    "                                                 input_rhoana[DOJO_SLICE], \n",
    "                                                 input_gold[DOJO_SLICE],\n",
    "                                                 error_rate=error_rate,\n",
    "                                                 sureness_threshold=t,                                                 \n",
    "                                                 oversampling=False)\n",
    "    \n",
    "    best_index = vi_s.index(np.min(vi_s))\n",
    "    best_vi = vi_s[best_index]\n",
    "    best_sureness = surenesses[best_index]\n",
    "    \n",
    "    return best_vi, good_fixes, bad_fixes, merge_pairs, vi_s\n",
    "\n",
    "def threed_vi(gt, seg):\n",
    "    total_vi = 0\n",
    "    slice_vi = []    \n",
    "    for i in range(10):\n",
    "        current_vi = Util.vi(gt[i].astype(np.int64), seg[i].astype(np.int64))\n",
    "        total_vi += current_vi\n",
    "        slice_vi.append(current_vi)\n",
    "    total_vi /= 10\n",
    "    return total_vi, slice_vi\n",
    "\n",
    "def user_threed_vi(gt, user):\n",
    "    total_vi = 0\n",
    "    slice_vi = []\n",
    "    for i in range(10):\n",
    "        current_vi = dojo_user_vi(user, i, gt[i])\n",
    "        total_vi += current_vi\n",
    "        slice_vi.append(current_vi)\n",
    "    total_vi /= 10\n",
    "    return total_vi, slice_vi\n",
    "    \n",
    "def cnn_threed_vi(cnn, input_image, input_prob, input_rhoana, input_gold):\n",
    "    total_vi = 0\n",
    "    slice_vi = []\n",
    "    slice_sureness = []\n",
    "    for i in range(10):\n",
    "        current_vi, sureness = fix_dojo_slice(cnn, i, input_image, input_prob, input_rhoana, input_gold)\n",
    "        total_vi += current_vi\n",
    "        slice_vi.append(current_vi)\n",
    "        slice_sureness.append(sureness)\n",
    "    total_vi /= 10\n",
    "    return total_vi, slice_vi, slice_sureness\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image, input_prob, input_gold, input_rhoana, dojo_bbox = Util.read_dojo_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/home/d/nets/MergeNet_larger_border_overlap_cylinder1_dataaugmentation/net.p', 'rb') as f:\n",
    "    cnn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/d/dojo_xp/data/dojo_data_vis2014_patches_predicted.p', 'rb') as f:\n",
    "    patches = pickle.load(f)\n",
    "new_patches = []\n",
    "for p in patches:\n",
    "    p_new = {}\n",
    "    p_new['image'] = p['image'] / 255.\n",
    "    p_new['prob'] = p['prob'] / 255.\n",
    "    p_new['merged_array'] = p['merged_array'] \n",
    "    p_new['border_overlap'] = p['border_overlap'] \n",
    "    new_patches.append(p_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix one slice a time with sureness threshold .95\n",
    "vol_vi_s = []\n",
    "for z in range(10):\n",
    "    vi_s, merge_pairs, surenesses = Fixer.splits(cnn, input_image[z], input_prob[z], input_rhoana[z], input_gold[z], \n",
    "                                                 sureness_threshold=.95,\n",
    "                                                 verbose=False)\n",
    "    vol_vi_s.append(vi_s[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51614654679457939"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(vol_vi_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 generated in 7.46155190468 seconds.\n",
      "Grouped into 116 patches in 0.00204300880432 seconds.\n",
      "448 generated in 9.67917203903 seconds.\n",
      "Grouped into 112 patches in 0.00206303596497 seconds.\n",
      "456 generated in 9.83008408546 seconds.\n",
      "Grouped into 113 patches in 0.00214004516602 seconds.\n",
      "484 generated in 10.1369900703 seconds.\n",
      "Grouped into 121 patches in 0.0022189617157 seconds.\n",
      "508 generated in 10.6413669586 seconds.\n",
      "Grouped into 127 patches in 0.00235080718994 seconds.\n",
      "488 generated in 10.3497629166 seconds.\n",
      "Grouped into 122 patches in 0.00232195854187 seconds.\n",
      "480 generated in 10.1295230389 seconds.\n",
      "Grouped into 118 patches in 0.00224614143372 seconds.\n",
      "460 generated in 9.77528500557 seconds.\n",
      "Grouped into 113 patches in 0.00211215019226 seconds.\n",
      "488 generated in 10.1580781937 seconds.\n",
      "Grouped into 120 patches in 0.00228404998779 seconds.\n",
      "540 generated in 11.1410880089 seconds.\n",
      "Grouped into 135 patches in 0.00248503684998 seconds.\n"
     ]
    }
   ],
   "source": [
    "# simulate user with error rate 0 with limit of N corrections\n",
    "bigM, out_vol, global_volume = Fixer.splits_global(cnn, input_image, input_prob, input_rhoana, input_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4144289172505391"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_simulated_vi = threed_vi(input_gold, out_vol)\n",
    "np.median(user_simulated_vi[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 generated in 7.42999410629 seconds.\n",
      "Grouped into 116 patches in 0.00201487541199 seconds.\n",
      "448 generated in 9.59283494949 seconds.\n",
      "Grouped into 112 patches in 0.00198411941528 seconds.\n",
      "456 generated in 9.68686699867 seconds.\n",
      "Grouped into 113 patches in 0.0021059513092 seconds.\n",
      "484 generated in 10.0097439289 seconds.\n",
      "Grouped into 121 patches in 0.00214195251465 seconds.\n",
      "508 generated in 10.4890110493 seconds.\n",
      "Grouped into 127 patches in 0.0022599697113 seconds.\n",
      "488 generated in 10.2200450897 seconds.\n",
      "Grouped into 122 patches in 0.00219798088074 seconds.\n",
      "480 generated in 10.0091488361 seconds.\n",
      "Grouped into 118 patches in 0.00214195251465 seconds.\n",
      "460 generated in 9.6586368084 seconds.\n",
      "Grouped into 113 patches in 0.00209379196167 seconds.\n",
      "488 generated in 10.0432958603 seconds.\n",
      "Grouped into 120 patches in 0.00227403640747 seconds.\n",
      "540 generated in 11.0135400295 seconds.\n",
      "Grouped into 135 patches in 0.00242280960083 seconds.\n"
     ]
    }
   ],
   "source": [
    "# random recommendations\n",
    "bigM, out_vol, global_volume = Fixer.splits_global(cnn, input_image, input_prob, input_rhoana, input_gold, randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47030797909077693"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_vi = threed_vi(input_gold, out_vol)\n",
    "np.median(random_vi[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 generated in 7.44634389877 seconds.\n",
      "Grouped into 116 patches in 0.00208497047424 seconds.\n",
      "448 generated in 9.60027599335 seconds.\n",
      "Grouped into 112 patches in 0.00206613540649 seconds.\n",
      "456 generated in 9.67844295502 seconds.\n",
      "Grouped into 113 patches in 0.00205779075623 seconds.\n",
      "484 generated in 10.0104978085 seconds.\n",
      "Grouped into 121 patches in 0.00217604637146 seconds.\n",
      "508 generated in 10.5294861794 seconds.\n",
      "Grouped into 127 patches in 0.0022828578949 seconds.\n",
      "488 generated in 10.2322368622 seconds.\n",
      "Grouped into 122 patches in 0.0022189617157 seconds.\n",
      "480 generated in 10.026018858 seconds.\n",
      "Grouped into 118 patches in 0.00217914581299 seconds.\n",
      "460 generated in 9.6668651104 seconds.\n",
      "Grouped into 113 patches in 0.00210499763489 seconds.\n",
      "488 generated in 10.0534870625 seconds.\n",
      "Grouped into 120 patches in 0.00218987464905 seconds.\n",
      "540 generated in 11.0391199589 seconds.\n",
      "Grouped into 135 patches in 0.00241494178772 seconds.\n"
     ]
    }
   ],
   "source": [
    "# create bigM for the UI tool\n",
    "bigM, a, global_volume = Fixer.splits_global(cnn, input_image, input_prob, input_rhoana, input_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/d/dojo_xp/data/bigM_new_cnn.p', 'wb') as f:\n",
    "    pickle.dump(bigM, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from uitools import UITools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on slice 0\n",
      "working on slice 1\n",
      "working on slice 2\n",
      "working on slice 3\n",
      "working on slice 4\n",
      "working on slice 5\n",
      "working on slice 6\n",
      "working on slice 7\n",
      "working on slice 8\n",
      "working on slice 9\n",
      "merge error correction done after 1108.03680515 seconds\n"
     ]
    }
   ],
   "source": [
    "merge_errors = UITools.get_top5_merge_errors(cnn, input_image, input_prob, input_rhoana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/d/dojo_xp/data/merges_new_cnn.p', 'wb') as f:\n",
    "    pickle.dump(merge_errors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merge_errors[4][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1889.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join('/home/d/dojo_xp/data/ui_out/new_cnn_test_with_saving_times/times.p'), 'rb') as f:\n",
    "    c_t = pickle.load(f)\n",
    "    c_t = [int(v) for v in c_t]\n",
    "np.mean(c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
